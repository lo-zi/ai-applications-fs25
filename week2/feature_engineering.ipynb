{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "574e60b2",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56472139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0d3d6bc",
   "metadata": {},
   "source": [
    "This notebook create new features and mesures the the perfomance change in the model. The goal is to create features to increase the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e9228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/opt/anaconda3/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/lib/python3.11/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3051, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3106, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3311, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3493, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/cv/wxwr195s66nc12zx999qrc4r0000gn/T/ipykernel_2287/996764896.py\", line 4, in <module>\n",
      "    from sklearn.ensemble import RandomForestRegressor\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 14, in <module>\n",
      "    from scipy.sparse import csr_matrix, issparse\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/__init__.py\", line 267, in <module>\n",
      "    from ._csr import *\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_csr.py\", line 10, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ignore warnings\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/__init__.py:73\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     __check_build,\n\u001b[1;32m     71\u001b[0m     _distributor_init,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_chunking.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/__init__.py:267\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/scipy/sparse/_csr.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[1;32m     11\u001b[0m                            get_csr_submatrix)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast, get_index_dtype\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compressed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cs_matrix\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038f83f",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data to a pandas data frame\n",
    "df = pd.read_csv('original_apartment_data_analytics_hs24_with_lat_lon.csv', sep=',', encoding='utf-8')\n",
    "# Get number of rows and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7739ae",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b4884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(features, df, random_forest_model = RandomForestRegressor(random_state=42)):\n",
    "    df = df.sample(frac=1, random_state=42)\n",
    "    X, y = df[features], df['price']\n",
    "    scores = cross_val_score(random_forest_model, X, y, scoring=\"neg_root_mean_squared_error\", cv=5)\n",
    "    print('CV results RMSE:', np.round(scores))\n",
    "    print('Mean RMSE:', np.mean(np.round(scores, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e462d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6a8fe",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "- Remove apartments with empty columns\n",
    "- Remove apartments which price exceeds 6000.-\n",
    "- Remove apartments which price is lower than 1000.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbef35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total apartment before data cleaning:', len(df))\n",
    "\n",
    "# Remove missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Remove some 'extreme' values\n",
    "df = df.loc[(df['price'] >= 750) & \n",
    "            (df['price'] <= 8000)]\n",
    "\n",
    "print('Total apartment after data cleaning:', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef12414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before data cleaning Mean RMSE: -894.8\n",
    "\n",
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61970fc",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcadc433",
   "metadata": {},
   "source": [
    "### Create additional variables from the apartment's descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new variable\n",
    "df['room_per_m2'] = round(df['area'] / df['rooms'], 2)\n",
    "df['price_per_m2'] = round(df['price'] / df['area'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without new features the performance is: AVG RMSE: -862.86\n",
    "\n",
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without new features the performance is: AVG RMSE: -862.86\n",
    "\n",
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'price_per_m2']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fda3b3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 4px solid #0073e6; padding: 10px; background-color: #e6f2ff; color: black;\">\n",
    "  <strong>Question:</strong>Why is the performance, nearly perfect, when using the feature 'price_per_m2'?\n",
    "</div>\n",
    "<div style=\"border-left: 4px solid #0073e6; padding: 10px; background-color: #e6f2ff; color: black;\">\n",
    "  <strong>Answer:</strong> <span style=\"background-color: black; color: black;\" onmouseover=\"this.style.color='white'\" onmouseout=\"this.style.color='black'\">The feature 'price_per_m2' represents the price per square meter, which is the target variable we aim to predict. If you know both the area and 'price_per_m2', calculating the total price becomes straightforward.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28903b28",
   "metadata": {},
   "source": [
    "#### Create new binary (0/1) variable 'luxurious'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern which can be used to search the variable 'description_raw'\n",
    "pattern = '(LOFT)|(SEESICHT)|(ATTIKA)|(LUXURIÖS)|(LUXU)|(POOL)|(EXKLUSIV)'\n",
    "\n",
    "# Create new variable 'luxurious' as binary dummy (0/1) variable\n",
    "df['luxurious'] = df['description_raw'].str.contains(pat = pattern).astype(int)\n",
    "print('Total of Luxurious Apartments', df['luxurious'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9bd905",
   "metadata": {},
   "source": [
    "#### Create new binary (0/1) variable 'temporary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be511311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern which can be used to search the variable 'description_raw'\n",
    "pattern = '(TEMPOR)|(BEFRIST)'\n",
    "\n",
    "# Create new variable 'luxurious' as binary dummy (0/1) variable\n",
    "df['temporary'] = df['description_raw'].str.contains(pat = pattern).astype(int)\n",
    "print('Total of Temporary Apartments', df['temporary'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c901d",
   "metadata": {},
   "source": [
    "#### Create new binary (0/1) variable 'furnished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8794d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern which can be used to search the variable 'description_raw'\n",
    "pattern = '(FURNISHED)|(MÖBLIERT)|(FURNISHE)'\n",
    "\n",
    "# Create new variable 'luxurious' as binary dummy (0/1) variable\n",
    "df['furnished'] = df['description_raw'].str.contains(pat = pattern).astype(int)\n",
    "print('Total of Furnished Apartments', df['furnished'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without new features the performance is: AVG RMSE: -862.86\n",
    "\n",
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f359fa",
   "metadata": {},
   "source": [
    "#### Create new categorical variable based on apartment area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8cbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0 - 49', '50 - 99', '100 - 500']\n",
    "df[\"area_cat\"] = pd.cut(df.area, bins=[0, 50, 100, 500], labels=labels)\n",
    "df[['area', 'area_cat']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ae7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "area_cat = df['area_cat'].values.reshape(-1,1)\n",
    "ordinal_encoding = OrdinalEncoder()\n",
    "area_cat_encoded = ordinal_encoding.fit_transform(area_cat) \n",
    "\n",
    "df['area_cat_ecoded'] = area_cat_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without new features the performance is: AVG RMSE: -862.86\n",
    "\n",
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d456214",
   "metadata": {},
   "source": [
    "### Luxurious One Hot Encoding\n",
    "One-Hot Encoding is a technique used in machine learning to convert categorical variables into a binary (0/1) format. Each unique category is represented as a separate column, and a 1 is assigned if that category is present, otherwise, it's 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837b630",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "| description_raw                                         | (ATTIKA) | (EXKLUSIV) | (LOFT) | (LUXURIÖS) | (POOL) | (SEESICHT) | (NONE) |\n",
    "|---------------------------------------------------------|----------|------------|--------|------------|--------|------------|--------|\n",
    "| Dieses Apartment ist sehr LUXURIÖS mit POOL.           | 0        | 0          | 0      | 1          | 1      | 0          | 0      |\n",
    "| Ein tolles LOFT mit SEESICHT und EXKLUSIVEM Design.    | 0        | 1          | 1      | 0          | 0      | 1          | 0      |\n",
    "| Normale Wohnung ohne Extras.                           | 0        | 0          | 0      | 0          | 0      | 0          | 1      |\n",
    "| Schöne Aussicht, aber keine besonderen Merkmale.       | 0        | 0          | 0      | 0          | 0      | 0          | 1      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to test one hot encoding with multiple categories\n",
    "#df.loc[0, \"description_raw\"] = 'Ein tolles LOFT mit SEESICHT und EXKLUSIVEM Design.'\n",
    "#df.iloc[0].description_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7568b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define terms for encoding\n",
    "terms = {'(ATTIKA)', '(EXKLUSIV)', '(LOFT)', '(LUXURIÖS)', '(POOL)', '(SEESICHT)'}\n",
    "\n",
    "# Create one-hot encoded columns\n",
    "for term in terms:\n",
    "    df[term] = df['description_raw'].str.contains(term.strip(\"()\"), case=False, na=False).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb20402",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded',\n",
    "       '(LUXURIÖS)', '(POOL)', '(SEESICHT)',\n",
    "       '(EXKLUSIV)', '(ATTIKA)', '(LOFT)']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a6ac8",
   "metadata": {},
   "source": [
    "### Split Zurich into Kreis\n",
    "\n",
    "<div style=\"border-left: 4px solid #0073e6; padding: 10px; background-color: #e6f2ff; color: black;\">\n",
    "  <strong>Note:</strong>To obtain the latitude and longitude, please refer to the slides attachment. We haven't included them here because they are extracted from an API, and if every student attempts to retrieve them, the API may not respond well. 😉\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15458d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfs_number_counts = df.groupby(['bfs_number', 'town']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "print(bfs_number_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c635f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "# Convert lat/lon to Shapely Points\n",
    "df['geometry'] = df.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
    "\n",
    "# Load GeoDataFrame with polygons of the city of Zurich\n",
    "gdf = gpd.read_file('stzh.adm_stadtkreise_a.json')\n",
    "\n",
    "# Initialize one-hot encoding columns with 0s\n",
    "for name in gdf['bezeichnung']:\n",
    "    df[name] = 0  \n",
    "\n",
    "# Iterate through each polygon and check if the points are inside\n",
    "for _, row in gdf.iterrows():\n",
    "    polygon_name = row['bezeichnung']\n",
    "    polygon_geom = row['geometry']\n",
    "    \n",
    "    # Check if each point is inside the polygon and update the corresponding column\n",
    "    df[polygon_name] = df['geometry'].apply(lambda point: 1 if polygon_geom.contains(point) else 0)\n",
    "\n",
    "# Drop the geometry column (optional)\n",
    "df.drop(columns=['geometry'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b8da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.bfs_number == 261][['town', 'address', \"Kreis 1\", \"Kreis 2\", \"Kreis 3\", \"Kreis 4\", \n",
    "        \"Kreis 5\", \"Kreis 6\", \"Kreis 7\", \"Kreis 8\", \n",
    "        \"Kreis 9\", \"Kreis 10\", \"Kreis 11\", \"Kreis 12\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded',\n",
    "       '(LUXURIÖS)', '(POOL)', '(SEESICHT)',\n",
    "       '(EXKLUSIV)', '(ATTIKA)', '(LOFT)', 'Kreis 6', 'Kreis 11', 'Kreis 12', 'Kreis 10',\n",
    "       'Kreis 4', 'Kreis 1', 'Kreis 9', 'Kreis 5', 'Kreis 7', 'Kreis 3',\n",
    "       'Kreis 2', 'Kreis 8']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c8a49",
   "metadata": {},
   "source": [
    "### Fix pop_dens and pop of city of zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838f9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the DataFrame with pop and pop_dens for each Kreis\n",
    "data = {\n",
    "    \"ID\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    \"Kreis\": [\n",
    "        \"Kreis 1\", \"Kreis 2\", \"Kreis 3\", \"Kreis 4\", \n",
    "        \"Kreis 5\", \"Kreis 6\", \"Kreis 7\", \"Kreis 8\", \n",
    "        \"Kreis 9\", \"Kreis 10\", \"Kreis 11\", \"Kreis 12\"\n",
    "    ],\n",
    "    \"pop\": [5890, 37639, 50950, 29944, 15874, 35688, 39647, 17860, 59841, 41411, 78801, 33537],\n",
    "    \"pop_dens\": [3232, 3254, 5792, 10008, 7942, 6932, 2574, 3704, 4729, 4512, 5736, 5470]\n",
    "}\n",
    "\n",
    "zuerich_pop_dens = pd.DataFrame(data)\n",
    "zuerich_pop_dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying pop and pop_dens to df of Zurich\n",
    "kreis_columns = ['Kreis 6', 'Kreis 11', 'Kreis 12', 'Kreis 10', 'Kreis 4', 'Kreis 1', 'Kreis 9', 'Kreis 5', 'Kreis 7', 'Kreis 3', 'Kreis 2', 'Kreis 8']\n",
    "\n",
    "for kreis_nr in kreis_columns:\n",
    "    df.loc[df[kreis_nr] == 1, 'pop'] = zuerich_pop_dens[zuerich_pop_dens['Kreis'] == kreis_nr]['pop'].values[0]\n",
    "    df.loc[df[kreis_nr] == 1, 'pop_dens'] = zuerich_pop_dens[zuerich_pop_dens['Kreis'] == kreis_nr]['pop_dens'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.bfs_number==261].pop_dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10519cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded',\n",
    "       '(LUXURIÖS)', '(POOL)', '(SEESICHT)',\n",
    "       '(EXKLUSIV)', '(ATTIKA)', '(LOFT)', 'Kreis 6', 'Kreis 11', 'Kreis 12', 'Kreis 10',\n",
    "       'Kreis 4', 'Kreis 1', 'Kreis 9', 'Kreis 5', 'Kreis 7', 'Kreis 3',\n",
    "       'Kreis 2', 'Kreis 8']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4640145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zurich_city'] = 0\n",
    "df.loc[df[kreis_columns].any(axis=1), 'zurich_city'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e563b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded',\n",
    "       '(LUXURIÖS)', '(POOL)', '(SEESICHT)',\n",
    "       '(EXKLUSIV)', '(ATTIKA)', '(LOFT)', 'Kreis 6', 'Kreis 11', 'Kreis 12', 'Kreis 10',\n",
    "       'Kreis 4', 'Kreis 1', 'Kreis 9', 'Kreis 5', 'Kreis 7', 'Kreis 3',\n",
    "       'Kreis 2', 'Kreis 8', 'zurich_city']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train random_forest_model = RandomForestRegressor()\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_forest_model.fit(df[features], df.price)\n",
    "\n",
    "cols = random_forest_model.feature_names_in_\n",
    "\n",
    "# Derive feature importance from random forest\n",
    "importances = random_forest_model.feature_importances_\n",
    "std         = np.std([tree.feature_importances_ for tree in random_forest_model.estimators_], axis=0)\n",
    "indices     = np.argsort(importances)[::-1]\n",
    "\n",
    "# Barplot with feature importance\n",
    "df_fi = pd.DataFrame({'features':cols,'importances': importances})\n",
    "df_fi.sort_values('importances', inplace=True)\n",
    "df_fi.plot(kind='barh', \n",
    "           y='importances',\n",
    "           x='features', \n",
    "           color='darkred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3160d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded', 'zurich_city']\n",
    "model_performance(features, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01369b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train random_forest_model = RandomForestRegressor()\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_forest_model.fit(df[features], df.price)\n",
    "\n",
    "cols = random_forest_model.feature_names_in_\n",
    "\n",
    "# Derive feature importance from random forest\n",
    "importances = random_forest_model.feature_importances_\n",
    "std         = np.std([tree.feature_importances_ for tree in random_forest_model.estimators_], axis=0)\n",
    "indices     = np.argsort(importances)[::-1]\n",
    "\n",
    "# Barplot with feature importance\n",
    "df_fi = pd.DataFrame({'features':cols,'importances': importances})\n",
    "df_fi.sort_values('importances', inplace=True)\n",
    "df_fi.plot(kind='barh', \n",
    "           y='importances',\n",
    "           x='features', \n",
    "           color='darkred')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae305ce",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da5c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all predictions for the training set.\n",
    "\n",
    "# train random_forest_model = RandomForestRegressor()\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_forest_model.fit(df[features], df.price)\n",
    "\n",
    "price_prediction = random_forest_model.predict(df[features])\n",
    "df_with_residual = pd.DataFrame(df[features], columns=df[features].columns, copy=True)\n",
    "df_with_residual['recidual (error)'] = np.abs(price_prediction - df.price)\n",
    "df_with_residual['price'] = df.price\n",
    "df_with_residual['predicted_price'] = price_prediction\n",
    "print(df_with_residual.head())\n",
    "# Add text, postalcode and town name\n",
    "# we use join instead of merge, because we 'join' on the index column and do not perform a merge using a specific column\n",
    "df_with_residual = df_with_residual.join(df[['description_raw', 'bfs_name', 'postalcode', 'town']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which location has the largest errors.\n",
    "df_with_residual[(df_with_residual['recidual (error)'] > 500)].groupby(['pop', 'bfs_name']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a79772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_with_residual[(df_with_residual['recidual (error)'] > 800)].to_csv('data_with_large_residuals.csv', \n",
    "          sep=\",\", \n",
    "          encoding='utf-8',\n",
    "          index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e54909",
   "metadata": {},
   "source": [
    "## Find the best parameters\n",
    "- GridSearch\n",
    "- RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000]}\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=3,\n",
    "scoring='neg_root_mean_squared_error', verbose = 2)\n",
    "grid_search.fit(df[features], df.price)\n",
    "\n",
    "# get best estimator:\n",
    "grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['rooms', 'area', 'pop', 'pop_dens', 'frg_pct', 'emp', 'tax_income', 'room_per_m2', 'luxurious', 'temporary', 'furnished', 'area_cat_ecoded', 'zurich_city']\n",
    "model_performance(features, df)\n",
    "\n",
    "print('After GridSearch')\n",
    "model_performance(features, df, RandomForestRegressor(n_estimators=1000, random_state=42))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa51a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [90, 100, 110],\n",
    "'max_features': [6, 9],\n",
    "'min_samples_leaf': [4, 5],\n",
    "'min_samples_split': [10, 12],\n",
    "'n_estimators': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "clf = RandomizedSearchCV(RandomForestRegressor(random_state=42), param_grid, random_state=0, n_iter=10, verbose=2)\n",
    "search = clf.fit(df[features], df.price)\n",
    "\n",
    "print(search.best_estimator_)\n",
    "model_performance(features, df, search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf87a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('apartments_data_enriched_with_new_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
